{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP PyTorch - Template.ipynb",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xL1QubTS9Gw",
        "colab_type": "text"
      },
      "source": [
        "# Objetivos deste trabalho\n",
        "- Familiarizar-se com a biblioteca PyTorch\n",
        "- Definir arquiteturas MLP simples em PyTorch\n",
        "- Treinar utilizando CIFAR10, testando diferentes arquiteturas, parâmetros, funções de loss e otimizadores\n",
        "- Comparar os resultados obtidos utilizando apenas Perpceptrons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Op1RhtS9Gx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "from random import shuffle\n",
        "import time\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ_fO7GdS9G0",
        "colab_type": "code",
        "outputId": "63264e6d-f72b-491f-f518-de65a3906e56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Carregar os datasets\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    #transforms.Grayscale(num_output_channels=1),\n",
        "\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset_train = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "dataset_test = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "test, val = random_split(dataset_test, lengths = (5000,5000))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L4eKn-4cZvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuHdgr35S9G5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(dataset=dataset_train, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test, shuffle=False)\n",
        "val_loader = DataLoader(dataset=val, shuffle=False)\n",
        "dataloaders = {'train': train_loader, 'val':val_loader, 'test' : test_loader }\n",
        "dataset_sizes = {'train' : len(train_loader.dataset), 'test' : len(test_loader.dataset), 'val': len(val_loader.dataset)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnQy6TmOS9G7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Definir a arquitetura MLP\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(32*32, 20)\n",
        "        self.fc2 = nn.Linear(20, 10)\n",
        "        self.activation_function = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 32*32)\n",
        "        x = self.activation_function(self.fc1(x))\n",
        "        x = self.activation_function(self.fc2(x))\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgToFgglS9HF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Realizar o treinamento aqui\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "  since = time.time()\n",
        "\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0.0\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "      print('-' * 10)\n",
        "\n",
        "      # Each epoch has a training and validation phase\n",
        "      for phase in ['train', 'val']:\n",
        "          if phase == 'train':\n",
        "              model.train()  # Set model to training mode\n",
        "          else:\n",
        "              model.eval()   # Set model to evaluate mode\n",
        "\n",
        "          running_loss = 0.0\n",
        "          running_corrects = 0\n",
        "\n",
        "          # Iterate over data.\n",
        "          for inputs, labels in dataloaders[phase]:\n",
        "              inputs = inputs.to(device)\n",
        "              labels = labels.to(device)\n",
        "\n",
        "              # zero the parameter gradients\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              # forward\n",
        "              # track history if only in train\n",
        "              with torch.set_grad_enabled(phase == 'train'):\n",
        "                  outputs = model(inputs)\n",
        "                  _, preds = torch.max(outputs, 1)\n",
        "                  loss = criterion(outputs, labels)\n",
        "\n",
        "                  # backward + optimize only if in training phase\n",
        "                  if phase == 'train':\n",
        "                      loss.backward()\n",
        "                      optimizer.step()\n",
        "\n",
        "              # statistics\n",
        "              running_loss += loss.item() * inputs.size(0)\n",
        "              running_corrects += torch.sum(preds == labels.data)\n",
        "          if phase == 'train':\n",
        "              scheduler.step()\n",
        "\n",
        "          epoch_loss = running_loss / dataset_sizes[phase]\n",
        "          epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "          print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "              phase, epoch_loss, epoch_acc))\n",
        "\n",
        "          # deep copy the model\n",
        "          if phase == 'val' and epoch_acc > best_acc:\n",
        "              best_acc = epoch_acc\n",
        "              best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "      print()\n",
        "\n",
        "  time_elapsed = time.time() - since\n",
        "  print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "      time_elapsed // 60, time_elapsed % 60))\n",
        "  print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "  # load best model weights\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioHN3_N_S9HI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Avaliar o modelo aqui (no conjunto de teste)\n",
        "def evaluate(model, data_loader):\n",
        "  acc = 0.0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for i, (inputs, labels) in enumerate(data_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        acc += torch.sum(pred == label.data)\n",
        "\n",
        "  print('Acc test_set: {:.4f}'.format(acc.double()/len(dataset_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPCjGJ6FS9G-",
        "colab_type": "code",
        "outputId": "937a3780-9271-4cc7-d313-e4c9c9c6213b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model = MLP()\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "  (fc1): Linear(in_features=1024, out_features=20, bias=True)\n",
            "  (fc2): Linear(in_features=20, out_features=10, bias=True)\n",
            "  (activation_function): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9Y7dfKMS9HC",
        "colab_type": "code",
        "outputId": "f6134458-61e3-4196-c182-327232a3b3d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Definir otimizador e loss\n",
        "# Nota: testar outros otimizadores e funções de loss (em particular cross entropy)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 4)\n",
        "num_epochs = 10\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=1024, out_features=20, bias=True)\n",
              "  (fc2): Linear(in_features=20, out_features=10, bias=True)\n",
              "  (activation_function): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HcXi27NaPPq",
        "colab_type": "code",
        "outputId": "c7839c36-e5c9-43f1-9b67-4bc47116a0bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "train_model(model, criterion, optimizer, scheduler, num_epochs )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 2.2966 Acc: 0.1374\n",
            "val Loss: 2.2878 Acc: 0.1824\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 2.2740 Acc: 0.1915\n",
            "val Loss: 2.2607 Acc: 0.1890\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 2.2465 Acc: 0.1956\n",
            "val Loss: 2.2370 Acc: 0.1860\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 2.2264 Acc: 0.1991\n",
            "val Loss: 2.2217 Acc: 0.2062\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 2.2179 Acc: 0.2082\n",
            "val Loss: 2.2198 Acc: 0.2092\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 2.2165 Acc: 0.2076\n",
            "val Loss: 2.2186 Acc: 0.2086\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 2.2152 Acc: 0.2091\n",
            "val Loss: 2.2174 Acc: 0.2112\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 2.2140 Acc: 0.2097\n",
            "val Loss: 2.2162 Acc: 0.2118\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 2.2133 Acc: 0.2108\n",
            "val Loss: 2.2161 Acc: 0.2114\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 2.2132 Acc: 0.2109\n",
            "val Loss: 2.2160 Acc: 0.2112\n",
            "\n",
            "Training complete in 9m 40s\n",
            "Best val Acc: 0.211800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=1024, out_features=20, bias=True)\n",
              "  (fc2): Linear(in_features=20, out_features=10, bias=True)\n",
              "  (activation_function): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDuB3HSOebnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}